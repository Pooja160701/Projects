# ğŸ§ **Spotify Azure Data Engineering End-to-End Project (With CI/CD)**

## ğŸ“Œ **Project Overview**

This project is a **complete, production-ready Azure Data Engineering Platform** built using the Spotify dataset.
It implements a **Medallion Architecture (Bronze â†’ Silver â†’ Gold)** and includes:

âœ” **Incremental ingestion** (CDC-based)
âœ” **Backfill capability**
âœ” **Structured Streaming with Auto Loader**
âœ” **SCD Type-2 using Delta Live Tables (DLT)**
âœ” **Metadata-driven pipeline design**
âœ” **Dynamic SQL generation with Jinja**
âœ” **Star Schema modeling**
âœ” **Unity Catalog governance**
âœ” **CI/CD deployment with Databricks Asset Bundles**

This project replicates how modern enterprise data teams build **real-time, reliable, scalable pipelines**.

---

# ğŸ—ï¸ **Architecture Diagram**

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚        Azure SQL Database            â”‚
                    â”‚ (DimUser, DimTrack, DimDate, etc.)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Azure Data Factory (ADF)      â”‚
                        â”‚  â€¢ Incremental Ingestion       â”‚
                        â”‚  â€¢ Backfilling (from_date)     â”‚
                        â”‚  â€¢ Metadata-driven Pipelines   â”‚
                        â”‚  â€¢ Looping over tables         â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚     Azure Data Lake Gen2 (Bronze / Silver / Gold)  â”‚
              â”‚ Containers: bronze, silver, gold, cdc              â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚     Azure Databricks (Structured Streaming) â”‚
                 â”‚   Bronze â†’ Silver transformations           â”‚
                 â”‚   Auto Loader + Schema Evolution            â”‚
                 â”‚   OOP-based reusable transformations        â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Delta Live Tables (Gold Layer)            â”‚
                   â”‚ â€¢ SCD Type-2 Dimensions (Auto CDC)        â”‚
                   â”‚ â€¢ Fact Tables                              â”‚
                   â”‚ â€¢ Data Quality Expectations                â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Serverless SQL Warehouse (BI/ETL) â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   CI/CD with Databricks Asset Bundles    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ§° **Tech Stack**

### **Azure Services**

* Azure SQL Database
* Azure Data Factory
* Azure Data Lake Gen2 (ADLS)
* Azure Databricks
* Unity Catalog
* Logic Apps (Pipeline Failure Alerts)

### **Databricks Technologies**

* Delta Lake
* Auto Loader
* Structured Streaming
* Delta Live Tables
* Unity Catalog
* Databricks Asset Bundles (CI/CD)
* Serverless SQL Warehouse

### **Programming / Tools**

* PySpark
* SQL
* Jinja2 templating
* Python OOP (Reusable utilities)
* GitHub (Version Control)

---

# ğŸ¥‰ **Bronze Layer: Ingestion Using Azure Data Factory**

## âœ… Features Implemented

âœ” **Incremental Load** (CDC-based using updated_at)
âœ” **Initial Load + Incremental in one pipeline**
âœ” **Backfill logic (from_date parameter)**
âœ” **Watermarking using JSON file**
âœ” **Avoiding empty file creation**
âœ” **Dynamic file naming**
âœ” **Metadata-driven design (loop over all tables)**

### âœ” CDC JSON Structure

```
/bronze/DimUser_CDC/
   â”œâ”€ empty.json
   â”œâ”€ cdc.json   { "last_cdc": "2025-01-01" }
```

### âœ” Looping Pipeline Input

```json
[
  { "schema": "dbo", "table": "DimUser", "cdc_col": "updated_at", "from_date": "" },
  { "schema": "dbo", "table": "DimTrack", "cdc_col": "updated_at", "from_date": "" },
  { "schema": "dbo", "table": "DimDate", "cdc_col": "date",        "from_date": "" },
  { "schema": "dbo", "table": "DimArtist", "cdc_col": "updated_at","from_date": "" },
  { "schema": "dbo", "table": "FactStream","cdc_col": "stream_timestamp","from_date": "" }
]
```

---

# ğŸ¥ˆ **Silver Layer: Databricks Streaming Using Auto Loader**

### **Key Concepts**

âœ” Bronze â†’ Silver using **cloudFiles Auto Loader**
âœ” **Schema Evolution** (add new columns)
âœ” **Rescued Data column handling**
âœ” **Reusable transformation utilities**
âœ” **Deduplication**
âœ” **Delta Tables** creation using `toTable()`

---

## **Example: Silver DimUser**

### ğŸ“¥ Streaming Read

```python
df = spark.readStream.format("cloudFiles") \
    .option("cloudFiles.format", "parquet") \
    .option("cloudFiles.schemaLocation", "abfss://silver/.../DimUser/checkpoint") \
    .load("abfss://bronze/.../DimUser")
```

### ğŸ”§ Reusable Transformation Class

```python
class reusable:
    def dropColumns(self, df, columns):
        return df.drop(*columns)
```

### âœ¨ Transformations

* Convert username â†’ UPPERCASE
* Drop rescued data
* Deduplicate on `user_id`

### ğŸ’¾ Write to Delta + Register as Table

```python
df.writeStream.format("delta") \
    .outputMode("append") \
    .option("checkpointLocation", "abfss://silver/.../checkpoint") \
    .trigger(once=True) \
    .toTable("spotify_cata.silver.DimUser")
```

---

# ğŸ¥‡ **Gold Layer: Delta Live Tables (DLT)**

## âœ” SCD Type-2 (Auto CDC Flow)

Implemented for:

* DimUser
* DimTrack
* DimArtist
* DimDate
* FactStream

### Example (DimUser)

```python
import dlt

@dlt.table
def dimuser_stg():
    return spark.readStream.table("spotify_cata.silver.dimuser")

dlt.create_streaming_table("dimuser")

dlt.create_auto_cdc_flow(
    target="dimuser",
    source="dimuser_stg",
    keys=["user_id"],
    sequence_by="updated_at",
    stored_as_scd_type=2
)
```

---

# âœ” **Delta Live Tables: Expectations (Data Quality)**

### Example Rules

```python
expectations = {
    "rule1": "user_id IS NOT NULL",
    "rule2": "updated_at IS NOT NULL"
}
```

### Apply Expectations

```python
dlt.create_streaming_table(
    name="dimuser",
    expect_all_or_drop=expectations
)
```

---

# â­ **Metadata-Driven SQL Using Jinja**

### Parameters

```python
parameters = [
  {"table": "spotify_cata.silver.factstream", "alias": "f", "cols": "f.stream_id, f.listen_duration"},
  {"table": "spotify_cata.silver.dimuser", "alias": "u", "cols": "u.user_id, u.user_name", "condition": "f.user_id = u.user_id"}
]
```

### Template

```python
from jinja2 import Template
query = Template(query_text).render(parameters=parameters)
```

Generates fully dynamic SQL queries for star-schema joins.

---

# ğŸš€ **CI/CD With Databricks Asset Bundles**

### YAML: `databricks.yml`

```yaml
bundle:
  name: spotify_dab

targets:
  dev:
    mode: development
    default: true
    workspace:
      host: https://...
  prod:
    mode: production
    workspace:
      host: https://...
```

### Commands

```bash
databricks bundle validate
databricks bundle summary
databricks bundle deploy --target dev
```

This enables **repeatable deployments** of notebooks, jobs, DLT pipelines across environments.

---

# ğŸ“Š **Star Schema Model**

### **Dimensions**

* DimUser
* DimArtist
* DimTrack
* DimDate

### **Fact Table**

* FactStream (listening activity)

---

# ğŸ“ **Project Folder Structure**

```
Spotify-Data-Engineering-Project/
â”‚
â”œâ”€â”€ source_scripts/
â”‚   â”œâ”€â”€ spotify_initial_load.sql
â”‚
â”œâ”€â”€ spotify_dab/
â”‚   â”œâ”€â”€ .databricks
â”‚   â”‚   â””â”€â”€ bundle
â”‚   â”‚       â””â”€â”€ dev
â”‚   â”‚       â””â”€â”€ prod
â”‚   â”œâ”€â”€ .vscode
â”‚   â”œâ”€â”€ Jinja
â”‚   â”‚   â””â”€â”€ jinja_notebook.py
â”‚   â”œâ”€â”€ resources
â”‚   â”œâ”€â”€ src
â”‚   â”‚   â””â”€â”€ gold
â”‚   â”‚       â””â”€â”€ dlt
â”‚   â”‚           â””â”€â”€ explorations
â”‚   â”‚               â””â”€â”€ sample_exploration.py
â”‚   â”‚           â””â”€â”€ transformations
â”‚   â”‚           â””â”€â”€ utilities
â”‚   â”‚   â””â”€â”€ silver
â”‚   â”‚       â””â”€â”€ silver_Dimensions.py
â”‚   â”œâ”€â”€ utils
â”œâ”€â”€ cdc.json
â”œâ”€â”€ empty.json
â”œâ”€â”€ loop_input
â””â”€â”€ README.md
```

---

# ğŸ **Final Output**

By the end of the project:

âœ” All Bronze â†’ Silver â†’ Gold tables created
âœ” Auto Loader streaming ingestion running
âœ” Delta Live Tables running with SCD Type-2
âœ” Metadata-driven joins working with Jinja
âœ” CI/CD ready for dev â†’ prod deployment
âœ” Full Medallion Lakehouse architecture completed

---

# ğŸ‰ **Completed Successfully**

This project showcases **enterprise-level Azure + Databricks engineering**, covering:

âœ” Data ingestion
âœ” Data transformation
âœ” Streaming pipelines
âœ” Lakehouse architecture
âœ” Orchestration
âœ” Governance
âœ” Automation
âœ” Deployment

A complete real-world system â€” end to end.